\chapter*{Conclusion}				   	   % DO NOT TOUCH!
\addcontentsline{toc}{chapter}{Conclusion} % DO NOT TOUCH!

The objective of this thesis was to implement an iterative parallel LUP (Lower-Upper decomposition with Pivoting) algorithm, analyze its performance in BDDCML (multilevel Balancing Domain Decomposition by Constraints solver Library), and compare it to other established LUP implementations.

The first part of the thesis introduced the hardware of CPUs and GPUs, providing a basic understanding of their suitability for computations.
The specifications of recent GPUs were also presented to strengthen the theoretical foundation.
The relevant aspects of the software layer for code orchestration on Nvidia GPUs, CUDA, were then introduced, along with parallel computation concepts used in the implementation.
Finally, the theoretical foundation concluded with the introduction of LUP algorithms and their application in solving systems of equations.

Then, the implementation of the project that encompassed procedures related to solving systems of equations using LUP was presented.
Building upon the information presented in the first chapter, the implementations of the LUP procedures were detailed.
Additionally, the unit tests, which assured the quality of the implemented algorithms, were presented, along with the benchmarks that were later used to evaluate the performance of the implementations.

Finally, the procedures implemented in the project were compared to established CUDA libraries in terms of execution speed and accuracy of results on a state-of-the-art HPC cluster.
The comparison of performance was facilitated through two benchmarks.
The first benchmark - Decomposition benchmark - evaluated the raw performance of the procedures on a set of 50 matrices with varying characteristics.
The second benchmark - BDDCML benchmark - involved assessing the performance of the procedures as part of BDDCML.\\
The results of the Decomposition benchmark revealed that among the procedures implemented, the PCM\_8PP (Parallel Crout's Method with Partial Pivoting and $8^2$ threads in each one-dimensional CUDA thread block) decomposer exhibited the most consistent performance, while the ICM\_32PP (Iterative Crout's Method with Partial Pivoting and 32-by-32 CUDA thread blocks) decomposer showed suitability only for specific types of matrices.
However, both decomposers performed worse compared to the CusolverDnXgetrf procedure provided by CUDA.
The implemented solver, IS\_\textit{x}PP (Iterative Solver with Partial Pivoting and \textit{x}-by-8 CUDA thread blocks), was deemed unusable as it occasionally provided invalid results.\\
The second benchmark revealed that ICM\_32PP was able to compete with CUDA's cusolverDnXgetrf and MAGMA's magma\_dgetrf\_gpu.
Specifically, the relaxed processing tolerance of the iterative approach of ICM\_32PP allowed it to complete the benchmark at 90\% of the speed of magma\_dgetrf\_gpu.

As mentioned in Section~\ref{Subsection:comparing-decomposers-and-solvers->decomposition-project-benchmarks->decomposers-benchmark->accuracy-of-results-on-all-matrices}, using the maximum absolute difference between actual and expected results as a measure of accuracy has its limitations.
Furthermore, the time-consuming nature of the accuracy measurements restricted the number of matrices that could be included in the benchmark.
Therefore, future work could include developing a more suitable and efficient approach for measuring the accuracy of results.
This revised approach could also help elucidate the issues highlighted in Sections~\ref{Subsection:comparing-decomposers-and-solvers->decomposition-project-benchmarks->decomposers-benchmark->accuracy-of-results-on-all-matrices} and \ref{Subsection:comparing-decomposers-and-solvers->decomposition-project-benchmarks->solvers-benchmark->accuracy-of-results-on-all-matrices}.
Further areas of future improvement could include refining the algorithm of ICM\_\textit{x}PP based on the benchmark results, and implementing project-based enhancements, such as automated benchmarks and automated processing of their results.
These enhancements would significantly contribute to the overall efficiency and effectiveness of the project.